{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking an algorithm used to solve a MAX-k-SAT problem\n",
    "\n",
    "In this notebook we showcase functionality of qubrabench by implementing and benchmarking a hillclimbing algorithm to solve MAX-k-SAT, as described in https://arxiv.org/abs/2203.04975.\n",
    "The paper describes two distinct variants of implementing the hillclimber: a simple hillclimber - which uses (quantum) search, and a steep one - which uses (quantum) max finding.\n",
    "\n",
    "## Problem Definition: MAX-k-SAT\n",
    "\n",
    "Max-k-SAT is a combinatorial optimization problem that given a list of clauses $(C_{i})^{p}_{i=1}$, each a disjunction of at most $k$ literals, and a set of weights $(w_{i})^{p}_{i=1}$, asks us to maximize the weight of the satisfied clauses,\n",
    "$$\\varphi(y) := \\sum ^{p} _{i=1} w_{i}C_{i}(y),$$\n",
    "over all assignments $y \\in \\{0, 1\\}^{q}$ of the variables. This problem is NP-hard for $k ≥ 2$.\n",
    "\n",
    "## Algorithm Definition: Hillclimber\n",
    "\n",
    "For a given MAX-k-SAT problem instace, we start with a random variable assignment $y \\in \\{0, 1\\}^{n}$ and look for improvements (higher values) of $\\varphi$ in the set of all bitstrings that differ from $y$ in at most $d$ bits. We will only use $d=1$ for now, so this can be assumed to be the value of $d$ from this point on. All bitstrings that differ from our current solution $y$ in at most $d$ bits are collectively called the neighbourhood $N_{d}(y)$ of $y$.\n",
    "\n",
    "### Simple Hillclimber\n",
    "The simple hill climber randomly samples such assignments until it finds one with a strictly higher value of $\\varphi$, which is then taken as the new assignment.\n",
    "This procedure is repeated until no further improvement is found.\n",
    "We can formalize each hillclimb step (described above) as searching for a solution in\n",
    "$$f:N_{d}(y) \\subseteq \\{0,1\\}^{n} →\\{0,1\\}$$\n",
    "$$f(z) = \\begin{cases}1 ~~~~~\\text{if}~ \\varphi(z)>\\varphi(y)\\\\ 0 ~~~~~\\text{otherwise} \\end{cases}$$\n",
    "\n",
    "### Steep Hillclimber\n",
    "\n",
    "The steep hillclimber calculates the value of $\\varphi$ for every neighbour $y^* \\in N_{d}(y)$ of $y$. It then finds the neigbour with the highest value of $\\varphi$ and uses this as the new assignment:\n",
    "$$y_{new} = max_{y^* \\in N_{d}(y)}(\\varphi(y^*))$$\n",
    "This procedure is repeated until no further improvement is found. \n",
    "\n",
    "# Solving a given problem instance\n",
    "\n",
    "As mentioned above, we can use a hillclimber algorithm to solve the MAX-k-SAT problem. For the purpose of simplicity within this notebook, we will be focussing on the steep hillclimber and a naive implementation of the hillclimber algorithm. This repository also contains a hillclimber algorithm, which uses a more advanced approach and has much better performance than the naive approach. However, as we are focussing on the functionality of qubrabench in this notebook, this more complex implementation will not be covered in more detail.\n",
    "\n",
    "## Implementing a naive steep hillclimber algorithm\n",
    "\n",
    "To solve a MAX-k-SAT problem instance, consisting of a set auf clauses $(C_{i})^{p}_{i=1}$ and a set of weights $(w_{i})^{p}_{i=1}$, we will implement a naive steep hillclimber algorithm. We start by importing two libraries we will need in the course of this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can solve any problem instances, we must first create the problem instances. Let's assume that $k=3$, which means we will be solving a MAX-3-SAT problem. We will also assume that we have four variables available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "var_count = 4\n",
    "demo_clauses_array = [[-1, -2, 3], [1, 2, -4], [-1, -2, 4]]\n",
    "demo_weights_array = [3, 5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this representation, each array in the demo_clauses_array represents one of the problems clauses. Each value in one of these clauses refers to one of the four available variables. If the value is negative, it represents a negated variable. The values in demo_weights_array represent the weight of the clause at the same index in the demo_clauses_array.\n",
    "\n",
    "Now that we have an array of clauses and an array of weights representing our problem instance, we can start implementing the solver for this problem.\n",
    "\n",
    "For this we implement a function, which randomly generates a sequence of zeros and ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_solution(variable_count):\n",
    "    return [random.randint(0, 1) for _ in range(variable_count)]\n",
    "\n",
    "\n",
    "random_assignment = generate_random_solution(var_count)\n",
    "print(random_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a sequence represents a random variable assignment $y$ for our problem instance. We then start out from this variable assignment and take a look at the socalled neighbours. These are other variable assignments, which differ from our current assignment in exactly one place. For example the variable assignment (0, 0, 0) has the neighbours (1, 0, 0), (0, 1, 0) and (0, 0, 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1]\n",
      "{(0, 0, 0, 1), (0, 0, 1, 0), (0, 1, 1, 1), (1, 0, 1, 1)}\n"
     ]
    }
   ],
   "source": [
    "def generate_differing_arrays(array, num_changes):\n",
    "    index_combinations = itertools.combinations(range(len(array)), num_changes)\n",
    "    arrays = set()\n",
    "\n",
    "    for indices in index_combinations:\n",
    "        for change_values in itertools.product([0, 1], repeat=num_changes):\n",
    "            new_array = list(array)\n",
    "            for i, j in zip(indices, change_values):\n",
    "                new_array[i] = j\n",
    "            arrays.add(tuple(new_array))\n",
    "\n",
    "    arrays.discard(tuple(array))\n",
    "    return list(arrays)\n",
    "\n",
    "\n",
    "def get_neighbours(solution, max_hamming_distance):\n",
    "    neighbours = set()\n",
    "    for i in range(1, max_hamming_distance + 1):\n",
    "        neighbours.update(generate_differing_arrays(solution, i))\n",
    "    return neighbours\n",
    "\n",
    "\n",
    "print(random_assignment)\n",
    "demo_neighbours = get_neighbours(random_assignment, 1)\n",
    "print(demo_neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these neighbours we need to calculate the weight the clause has with this solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current weight:\n",
      "[0, 0, 1, 1] 4\n"
     ]
    }
   ],
   "source": [
    "def calculate_weight_for_solution(solution, clauses_array, weights_array):\n",
    "    weight = 0\n",
    "    for i in range(len(clauses_array)):\n",
    "        for value in clauses_array[i]:\n",
    "            if value > 0:\n",
    "                if solution[value - 1] == 1:\n",
    "                    weight += weights_array[i]\n",
    "                    break\n",
    "            elif value < 0:\n",
    "                if solution[abs(value) - 1] == 0:\n",
    "                    weight += weights_array[i]\n",
    "                    break\n",
    "    return solution, weight\n",
    "\n",
    "\n",
    "print(\"Current weight:\")\n",
    "current_solution, current_weight = calculate_weight_for_solution(\n",
    "    random_assignment, demo_clauses_array, demo_weights_array\n",
    ")\n",
    "print(random_assignment, current_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbour weights:\n",
      "(0, 0, 0, 1) 4\n",
      "(0, 0, 1, 0) 9\n",
      "(0, 1, 1, 1) 9\n",
      "(1, 0, 1, 1) 9\n",
      "Highest weight: 9\n",
      "Highest solution: (0, 0, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "def find_better_neighbour(solution, weight, clauses_array, weights_array, distance):\n",
    "    highest_weight = -1\n",
    "    highest_solution = []\n",
    "\n",
    "    for neighbour in demo_neighbours:\n",
    "        solution, weight = calculate_weight_for_solution(\n",
    "            neighbour, demo_clauses_array, demo_weights_array\n",
    "        )\n",
    "        if weight > highest_weight:\n",
    "            highest_weight = weight\n",
    "            highest_solution = neighbour\n",
    "        print(solution, weight)\n",
    "    return highest_solution, highest_weight\n",
    "\n",
    "\n",
    "print(\"Neighbour weights:\")\n",
    "highest_solution, highest_weight = find_better_neighbour(\n",
    "    current_solution, current_weight, demo_clauses_array, demo_weights_array, d\n",
    ")\n",
    "\n",
    "print(\"Highest weight: \" + str(highest_weight))\n",
    "print(\"Highest solution: \" + str(highest_solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pick the neighbour with the highest weight, and if this weight is bigger than the current weight, we will use this solution and repeat this process until there is no more improvement. The optimal weight for a given assignment in this case is 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps we went through now form our hillclimber algorihm, which runs through this cycle multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with assignment: [0, 0, 0, 1]\n",
      "Starting weight: 4\n",
      "(0, 0, 0, 1) 4\n",
      "(0, 0, 1, 0) 9\n",
      "(0, 1, 1, 1) 9\n",
      "(1, 0, 1, 1) 9\n",
      "Found better weight: 9\n",
      "(0, 0, 0, 1) 4\n",
      "(0, 0, 1, 0) 9\n",
      "(0, 1, 1, 1) 9\n",
      "(1, 0, 1, 1) 9\n",
      "No better weight found.\n",
      "Completed. Optimal assignment: (0, 0, 1, 0). Weight: 9.\n"
     ]
    }
   ],
   "source": [
    "def hill_climber_sat(clauses_array, weights_array, variable_count, distance):\n",
    "    # Example assignment, chosen to be able to demonstrate multiple steps\n",
    "    current_solution = [0, 0, 0, 1]\n",
    "    print(\"Starting with assignment: \" + str(current_solution))\n",
    "\n",
    "    solution, weight = calculate_weight_for_solution(\n",
    "        current_solution, clauses_array, weights_array\n",
    "    )\n",
    "    print(\"Starting weight: \" + str(weight))\n",
    "    better_solution, better_weight = find_better_neighbour(\n",
    "        solution, weight, clauses_array, weights_array, distance\n",
    "    )\n",
    "\n",
    "    while weight < better_weight:\n",
    "        current_solution = better_solution\n",
    "        weight = better_weight\n",
    "        print(\"Found better weight: \" + str(weight))\n",
    "        better_solution, better_weight = find_better_neighbour(\n",
    "            current_solution, weight, clauses_array, weights_array, distance\n",
    "        )\n",
    "    print(\"No better weight found.\")\n",
    "    print(\n",
    "        \"Completed. Optimal assignment: \"\n",
    "        + str(better_solution)\n",
    "        + \". Weight: \"\n",
    "        + str(better_weight)\n",
    "        + \".\"\n",
    "    )\n",
    "\n",
    "\n",
    "hill_climber_sat(demo_clauses_array, demo_weights_array, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Spottig a pattern\n",
    "\n",
    "If we take another look at this approach, we will notice, that we calculate the maximum value of a set of numbers within the find_better_neighbour function. In this case the maximum weight in a set of weights of all neighbours. This library offers a function, which enables a user to do exactly this and to keep track of runtime stats and approximations for call counts, if the max function was run on a quantum machine.\n",
    "\n",
    "## Max Function\n",
    "\n",
    "The library includes a set of common functions you would need in various circumstances, for example the search and the max function. These return the result you would expect from other implementations of these functions, and at the same time add in quantum benchmarking functionality. This simultaneously makes it easier to understand the use-cases of the library and makes it relatively easy to adapt existing code to use quantum benchmarking.\n",
    "\n",
    "When we talk about quantum benchmarking here, we mean approximating the amount of calls needed to execute the function with identical parameters on a quantum computer. This library achieves this by counting the calls run on the classical (in this case most likely your) machine and basing performance assumptions on these measurements. All provided functions in qubrabench currently require a stats object, in which these collected statistics and approximations are stored.\n",
    "\n",
    "Let's take a look at the docstrings of the function we will need to solve our problem - max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "    Find the largest element in a list, while keeping track of query statistics.\n",
       "    \n",
       "    Args:\n",
       "        iterable: iterable to find the maximum in\n",
       "        default: default value to return if iterable is empty.\n",
       "        key: function that maps iterable elements to values that are comparable. By default, use the iterable elements.\n",
       "        error: upper bound on the failure probability of the quantum algorithm.\n",
       "        stats: object that keeps track of statistics.\n",
       "    \n",
       "    Raises:\n",
       "        ValueError: Raised when the failure rate `error` is not provided and statistics cannot be calculated.\n",
       "        ValueError: Raised when iterable is an empty sequence and no default is provided.\n",
       "    \n",
       "    Returns:\n",
       "        the desired maximum element\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "    Call self as a function."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from qubrabench.algorithms.max import max as qmax\n",
    "\n",
    "%pdoc qmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example will use the max function documented above. It may seem a bit confusing, that the values in the array (iterable) should be themselves arrays containing only a single integer, however this will be used here to demonstrate the use of the key function. We provide the max function with the described array and intend to receive the array containing the highest integer. The default value is set to [-1] here, such a value would indicate an empty iterable being passed to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[91]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qubrabench.algorithms.max import max\n",
    "\n",
    "max([[14], [2], [30], [7], [91]], default=[-1], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a basic understanding of how to use the max function, we can use it in our hillclimber algorithm. This will enable us to collect benchmarking results to approximate classical and quantum query counts for our problem instances. In the following section we will be running the hillclimber provided in this library, because it runs much faster for larger problem instances. This will nonetheless be sufficient to demonstrate how these benchmarking results may look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "The imported `run` function executes the hillclimber on a random instance and returns the statistics in a pandas DataFrame. As running the hillclimber also touches on some important topics on relation to the max function, we will also take a look at its code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_runs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrng\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_weights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"External interface to generate weighted sat instances, run the hillclimber algorithm and return statistics.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        k: Number of literals in a clause\u001b[0m\n",
       "\u001b[0;34m        r: Factor for the number of clauses\u001b[0m\n",
       "\u001b[0;34m        n: size (variable number) of the SAT instances\u001b[0m\n",
       "\u001b[0;34m        n_runs: number of runs to perform in each group\u001b[0m\n",
       "\u001b[0;34m        rng: Source of randomness\u001b[0m\n",
       "\u001b[0;34m        error: Upper bound on the failure rate. Defaults to None.\u001b[0m\n",
       "\u001b[0;34m        random_weights: Optionally providable weights for SAT instance generation. Defaults to None.\u001b[0m\n",
       "\u001b[0;34m        steep: Whether to perform hillclimb steep (greedily). Defaults to False.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns:\u001b[0m\n",
       "\u001b[0;34m        Dataframe holding benchmarking statistics of the runs performed.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32massert\u001b[0m \u001b[0mn_runs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mrun_ix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"k={k}, r={r}, n={n}, steep={steep}, #{run_ix}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# run hill climber on random instance\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeightedSatInstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_weights\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhill_climber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# save record to history\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# return pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hillclimber import run\n",
    "\n",
    "%psource run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we can run the hillclimber multiple times in this case and then compute the average of the results. In the loop we first generate a QueryStats object, as mentioned above, which is used to store the results of the hillclimber run. After that, we create a problem instance using our desired parameters. Once this is done we can run the hillclimber, providing all possible parameters, including `error`, `stats` and `steep`. In our case we require the stats in a pandas dataframe, which is why we convert the stats object into a dictionary, add some additional interesting stats and add it to the `history` array.\n",
    "\n",
    "Let's run the steep hill climber for $n = 100$, $n = 300$ and $n=1000$. We will run the hill climber five times for each $n$ and consistently use $k = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "%%time\n",
    "data_100 = run(\n",
    "    k=3,\n",
    "    r=3,\n",
    "    n=100,\n",
    "    n_runs=5,\n",
    "    rng=np.random.default_rng(seed=100),\n",
    "    error=10**-5,\n",
    "    steep=True,\n",
    ")\n",
    "data_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_300 = run(\n",
    "    k=3,\n",
    "    r=3,\n",
    "    n=300,\n",
    "    n_runs=5,\n",
    "    rng=np.random.default_rng(seed=100),\n",
    "    error=10**-5,\n",
    "    steep=True,\n",
    ")\n",
    "data_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_500 = run(\n",
    "    k=3,\n",
    "    r=3,\n",
    "    n=500,\n",
    "    n_runs=5,\n",
    "    rng=np.random.default_rng(seed=100),\n",
    "    error=10**-5,\n",
    "    steep=True,\n",
    ")\n",
    "data_500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Finally, after we have benchmarked the solving of a couple of our problem instances, we can take a look at the plotting functionality qubrabench provides. We use the `PlottingStrategy` wrapper to define our plot parameters and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubrabench.utils.plotting_strategy import PlottingStrategy\n",
    "\n",
    "\n",
    "class Plotter(PlottingStrategy):\n",
    "    def __init__(self):\n",
    "        self.colors[\"\"] = \"blue\"\n",
    "\n",
    "    def get_plot_group_column_names(self):\n",
    "        return [\"k\", \"r\"]\n",
    "\n",
    "    def get_data_group_column_names(self):\n",
    "        \"\"\"\n",
    "        Generate a data line for each unique value in the specified columns.\n",
    "        Useful if you the data was generated with different tags based on implementation source, parameter choice etc., that one wants to compare against in a single plot.\n",
    "\n",
    "        Example: [\"impl\"] - a line will be generated for each unique `impl` label.\n",
    "        \"\"\"\n",
    "        return []\n",
    "\n",
    "    def compute_aggregates(self, data, *, quantum_factor):\n",
    "        # compute combined query costs of quantum search\n",
    "        c = data[\"quantum_expected_classical_queries\"]\n",
    "        q = data[\"quantum_expected_quantum_queries\"]\n",
    "        data[\"quantum_cost\"] = c + quantum_factor * q\n",
    "        return data\n",
    "\n",
    "    def x_axis_column(self):\n",
    "        return \"n\"\n",
    "\n",
    "    def x_axis_label(self):\n",
    "        return \"$n$\"\n",
    "\n",
    "    def y_axis_label(self):\n",
    "        return \"Queries\"\n",
    "\n",
    "    def get_column_names_to_plot(self):\n",
    "        return {\n",
    "            \"classical_actual_queries\": (\"Classical Queries\", \"o\"),\n",
    "            \"quantum_cost\": (\"Quantum Queries\", \"x\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put all the benchmark stats in a single table and run the plotter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "    Plot benchmarking data.\n",
       "    \n",
       "    Args:\n",
       "        data: a pandas DataFrame containing all the benchmark data.\n",
       "        quantum_factor: conversion factor for the cost of a quantum query (w.r.t. classical queries).\n",
       "        y_lower_lim: lower limit on the Y-axis (useful if the data starts at a large value)\n",
       "    \n",
       "    Raises:\n",
       "        ValueError: if no columns are given to plot\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "    Call self as a function."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdoc Plotter.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mconcat([data_100, data_300, data_500])\n\u001b[1;32m      2\u001b[0m Plotter()\u001b[38;5;241m.\u001b[39mplot(data, quantum_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, y_lower_lim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data_100, data_300, data_500])\n",
    "Plotter().plot(data, quantum_factor=2, y_lower_lim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also run the \"steep\" hillclimber for the above instance sizes, and compare the two benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_steep = [\n",
    "    run(\n",
    "        k=3,\n",
    "        r=3,\n",
    "        n=n,\n",
    "        n_runs=5,\n",
    "        rng=np.random.default_rng(seed=100),\n",
    "        error=10**-5,\n",
    "        steep=True,\n",
    "    )\n",
    "    for n in [100, 300, 500]\n",
    "]\n",
    "data_steep = pd.concat(data_steep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an extra column to distinguish the source (i.e. type of hillclimb)\n",
    "full_data = []\n",
    "for d, is_steep in [(data, False), (data_steep, True)]:\n",
    "    d = d.copy()\n",
    "    d.insert(0, \"steep\", is_steep)\n",
    "    full_data.append(d)\n",
    "full_data = pd.concat(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the above plotter a bit as we now want to group the data by column \"steep\" (in the same plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullPlotter(Plotter):\n",
    "    def __init__(self):\n",
    "        self.colors[\"steep = False\"] = \"blue\"\n",
    "        self.colors[\"steep = True\"] = \"red\"\n",
    "\n",
    "    def get_data_group_column_names(self):\n",
    "        return [\"steep\"]\n",
    "\n",
    "\n",
    "FullPlotter().plot(full_data, quantum_factor=2, y_lower_lim=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
